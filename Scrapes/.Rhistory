set.seed(02162022)
genes <- paste("gene",1:1000,sep="")
x <- list(
A = sample(genes,300),
B = sample(genes,525),
C = sample(genes,440),
D = sample(genes,350)
)
library(ggvenn)
ggvenn(
x,
fill_color = c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF"),
stroke_size = 0.5, set_name_size = 4
)
y <- list(
EPI = c(1,2,3,8,9,10),
DS = c(4,5,6,11,12,13),
S = c(2,3,4,5,6,7)
)
ggvenn(
y,
fill_color = c("#0073C2FF", "#EFC000FF", "#868686FF"),
stroke_size = 0.5, set_name_size = 4)
z <- list(
EPI = c(1,2,3,8,9,10),
DS = c(4,5,6,7,8,9)
)
ggvenn(
z,
fill_color = c("#0073C2FF", "#868686FF"),
stroke_size = 0.5, set_name_size = 4)
cats <- list(
RD = c("Reading Data", "Theory", "Analysis"),
WD = c("Working with Data", "Collection", "Management"),
CD = c("Communicating with Data", "Reporting", "Presentation")
)
ggvenn(
cats,
fill_color = c("#0073C2FF", "#868686FF"),
stroke_size = 0.5, set_name_size = 4)
?seq()
seq(1, 5, by = .1)
plot(seq(1, 5, by = .1))
?rep()
plot(rep(seq(1, 5, by = .1), 5)
plot(rep(seq(1, 5, by = .1), 5))
plot(rep(seq(1, 5, by = .1), 5))
plot(rep(seq(1, 2, by = .1), 5))
plot(rep(seq(0, 1, by = .1), 5))
plot(rep(seq(0, 1, by = 1), 5))
plot(rep(seq(0, 1, by = .1), 5))
plot(rep(seq(0, 1, by = -1), 5))
plot(rep(seq(0, 1, by = .01), 5))
rdiag <- rep(seq(0, 1, by = .01), 5)
plot(rep(seq(1, 0, by = .01), 5))
plot(seq(seq(0, 1, .1), 1, .1))
plot(seq(1, 1, .1))
plot(seq(1, 1.5, .1))
seq(0, 5, .1)
x <- seq(0, 5, .1)
y <- 1
x <- seq(0, 5, .1)
y <- 1
plot(x,y)
y <- seq(1, 1, .1)
plot(x,y)
y <- seq(0, 5, .1)
plot(x,y)
x <- seq(0, 5, .1)
y <- list(1:1)
x <- list(1:10)
plot(x, y)
x <- c(1:10)
y <- c(1:1)
plot(x, y)
y <- c(1:10)
x <- c(1:10)
plot(x, y)
y <- rep(1, 10)
plot(x, y)
x <- rep(1, 10)
y <- c(1:10)
plot(x, y)
# Vertical straight line
x <- rep(1, 10)
y <- c(1:10)
plot(x, y)
y <- seq(1, 10, by = 1)
plot(x, y)
x <- rep(1, 10)
y <- seq(1, 10, by = 1)
plot(x, y)
y <- rep(seq(1, 10, by = 1), 2)
plot(x, y)
plot(x + 2, y)
y <- seq(1, 10, by = 1)
plot(x + 2, y)
x <- rep(1, 10)
y <- seq(1, 10, by = 1)
plot(x + 2, y)
plot(x, y)
x <- rep(1, 10)
y <- seq(1, 10, by = 1)
plot(x, y)
x <- rep(1, 20)
y <- rep(seq(1, 10, by = 1))
plot(x, y)
y <- rep(seq(1, 10, by = 1), 2)
plot(x, y)
#
x <- rep(seq(1, 10, 1), 2)
y = rep(seq(1, 10, 1), 2)
plot(x,y)
#
x <- rep(seq(1, 10, 1), 1)
y = rep(seq(1, 10, 1), 1)
plot(x,y)
rdiag <- rep(seq(0, 1, by = .01), 5)
ldiag <- rep(seq(1, 0, by = .01), 5)
plot(rdiag, ldiag)
ldiag <- rep(seq(1, 0, by = .01), 5)
ldiag <- rep(seq(1, 0, by = -.01), 5)
plot(rdiag, ldiag)
read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv")
read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.txt")
wedss <- read.delim("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.txt")
View(wedss)
wedss <- read.delim("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv")
View(wedss)
wedsscsv <- read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv")
wedsscsv <- read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv")
wedsstxt <- read.delim("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.txt")
wedsscsv <- read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv")
wedsscsv <- read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv", header = F, skip = 2)
View(wedsscsv)
wedsscsv <- read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv", header = F)
wedsscsv <- read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv", header = F)
View(wedsscsv)
library(dplyr)
# From WEDSS a text file was provided
# This was converted to a csv file type
# wedsstxt <- read.delim("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.txt")
# This would require too much parsing
# We rely on this csv format instead
wedss <- read.csv("C:/Users/Zachary.Palmore/Documents/Data/wedss_labresults_021720221226.csv", header = F)
View(wedss)
names(wedss)
library(janitor)
install.packages("janitor")
wedss[1,]
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
summary(cars)
plot(pressure)
library("utils")
daily_covid <- read.csv("G:/Staff/Zachary.Palmore/SuperReport/Daily_Covid_Data.csv")
daily_covid <- read.csv('H:/SuperReport/Daily_Covid_Data.csv')
daily_covid <- read.csv("C:/Users/Zachary.Palmore/Downloads/DailyCoviddata.csv")
View(daily_covid)
View(daily_covid)
names(daily_covid)
datanames <- c("Day", "Date", "NegativeTestResults", "PositiveResults", "ProbableCases", "Deaths", "Recovered")
library(tidyverse)
install.packages("tidyverse")
daily_covid %>%
rename(Day = "X",
Date = "X.1")
daily_covid[1:7,]
daily_covid[,1:7]
daily_covid2 <- daily_covid[,1:7]
names(daily_covid2) <- datanames
daily_covid2
library(dplyr)
daily_covid %>%
rename(Day = "X",
Date = "X.1")
library(tidyverse)
daily_covid %>%
rename(Day = "X",
Date = "X.1")
daily_covid
daily_covid %>%
rename(Day = "X",
Date = "X.1")
df <- daily_covid %>%
rename(Day = "X",
Date = "X.1")
View(df)
View(daily_covid)
daily_covid <- daily_covid %>%
rename(Day = "X",
Date = "X.1")
View(daily_covid)
daily_covid$Daily.new.positives - daily_covid$Daily.new.negatives
daily_covid$Daily.new.positives
class(daily_covid$Daily.new.positives)
class(daily_covid$Daily.new.negatives)
daily_covid$Daily.new.negatives
as.numeric(daily_covid$Daily.new.negatives)
daily_covid$Daily.new.negatives <- as.numeric(daily_covid$Daily.new.negatives)
sum(is.na(daily_covid$Daily.new.negatives))
which(is.na(daily_covid$Daily.new.negatives))
daily_covid$Daily.new.negatives[which(is.na(daily_covid$Daily.new.negatives))]
daily_covid$Daily.new.negatives[which(is.na(daily_covid$Daily.new.negatives))] <- 0
daily_covid$Daily.new.positives - daily_covid$Daily.new.negatives
daily_covid$X7.day.Moving.Average....
daily_covid$X7.day.Moving.Average....[719,]
daily_covid$X7.day.Moving.Average....[,719]
daily_covid$X7.day.Moving.Average....[719]
daily_covid$X7.day.Moving.Average....[723]
daily_covid$X7.day.Moving.Average....[722]
daily_covid$X7.day.Moving.Average....[721]
paste0("https://www.google.com/travel/hotels/",
"entity/CgoIqJbZ6P-Ala9aEAE/",
"reviews?q=holiday%20inn%20janesville%20wi",
"&g2lb=2502548%2C2503771%2C2503781%2C2504096%",
"2C4258168%2C4270442%2C4284970%2C4291517%2C4306835",
"%2C4597339%2C4718358%2C4723331%2C4757164%2C4801235",
"%2C4814050%2C4816977%2C4826689%2C4849799%2C4852066",
"%2C4861688%2C4865301%2C4871746%2C26483161",
"&hl=en-US&gl=us&ssta=1",
"&ts=CAESABpJCisSJzIlMHg4",
"ODA2MTA4ODViYjQ2MTJmOjB4NWE1ZTU0MDdmZD",
"E2NGIyOBoAEhoSFAoHCOYPEAsYEhIHCOYPEAsYExg",
"BMgIQACoJCgU6A1VTRBoA&qs=CAE4AkILCShLFv0HVF5",
"aGAFCCwkoSxb9B1ReWhgB&ictx=1",
"&sa=X&utm_campaign=sharing",
"&utm_medium=link&utm_source=htls",
"&ved=0CAAQ5JsGahcKEwiQuIu0qt36AhUAAAAAHQAAAAAQBA")
setwd("C:/Users/Zachary.Palmore/GitHub/misc/Scrapes")
require(rvest)
require(purrr)
require(dplyr)
url <- paste0("https://www.google.com/travel/hotels/",
"entity/CgoIqJbZ6P-Ala9aEAE/",
"reviews?q=holiday%20inn%20janesville%20wi",
"&g2lb=2502548%2C2503771%2C2503781%2C2504096%",
"2C4258168%2C4270442%2C4284970%2C4291517%2C4306835",
"%2C4597339%2C4718358%2C4723331%2C4757164%2C4801235",
"%2C4814050%2C4816977%2C4826689%2C4849799%2C4852066",
"%2C4861688%2C4865301%2C4871746%2C26483161",
"&hl=en-US&gl=us&ssta=1",
"&ts=CAESABpJCisSJzIlMHg4",
"ODA2MTA4ODViYjQ2MTJmOjB4NWE1ZTU0MDdmZD",
"E2NGIyOBoAEhoSFAoHCOYPEAsYEhIHCOYPEAsYExg",
"BMgIQACoJCgU6A1VTRBoA&qs=CAE4AkILCShLFv0HVF5",
"aGAFCCwkoSxb9B1ReWhgB&ictx=1",
"&sa=X&utm_campaign=sharing",
"&utm_medium=link&utm_source=htls",
"&ved=0CAAQ5JsGahcKEwiQuIu0qt36AhUAAAAAHQAAAAAQBA")
# url <- paste0(url_base, tack_search)
pg <- read_html(url)
View(pg)
html_nodes(pg)
html_nodes(pg, ".QB2Jof")
html_text(html_nodes(pg, ".QB2Jof"))
.K7oBsc span , #reviews .CQYfx , .QB2Jof
html_text(html_nodes(pg, "#reviews"))
.K7oBsc span , #reviews .CQYfx , .QB2Jof
html_text(html_nodes(pg, ".CQYfx"))
html_text(html_nodes(pg, ".K7oBsc"))
setwd("C:/Users/Zachary Palmore/GitHub/misc/Scrapes")
require(rvest)
require(purrr)
require(dplyr)
# Scrape Once:
url_base_madison <- "https://www.linkedin.com/jobs/search?keywords=Data&location=Greater%20Madison%20Area&geoId=90000472&trk=public_jobs_jobs-search-bar_search-submit&position=1"
url_page_number <- paste0("&pageNum=", 0)
url_read_html <- paste0(url_base_madison, url_page_number)
pg <- read_html(url_read_html)
df_all <- data.frame(
Page = as.numeric(999),
Company_Name=gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__subtitle"))),
Position_Name=gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__title"))),
Location_Name=gsub("\\W", "", html_text(html_nodes(pg, ".job-search-card__location"))),
stringsAsFactors=FALSE)
# Scrape Page 0 through X (You Specify)
for (i in 0:9){
start_time <- Sys.time()
cat(".")
Sys.sleep(runif(1, min = 35, max = 99))
url_page_number <- paste0("&pageNum=", i)
url_read_html <- paste0(url_base_madison, url_page_number)
pg <- read_html(url_read_html)
results <- data.frame(
Page = as.numeric(i),
Company_Name = gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__subtitle"))),
Position_Name = gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__title"))),
Location_Name = gsub("\\W", "", html_text(html_nodes(pg, ".job-search-card__location"))),
stringsAsFactors = FALSE)
df_all <- rbind(df_all, results)
end_time <- Sys.time()
time_needed <- end_time - start_time
print(paste("Step", i, "was finished after", time_needed, "seconds."))
}
View(df_all)
View(df_all)
writeLines(unique(df_all$Company_Name), "exports/companies_madison7.csv", sep = ",")
write.csv(df_all, "exports/Madison7.csv")
require(rvest)
require(purrr)
require(dplyr)
# Scrape Once:
url_base_milwaukee <- "https://www.linkedin.com/jobs/search?keywords=Data&location=Greater%20Milwaukee&geoId=90000063&trk=public_jobs_jobs-search-bar_search-submit&position=1"
url_page_number <- paste0("&pageNum=", 0)
url_read_html <- paste0(url_base_milwaukee, url_page_number)
pg <- read_html(url_read_html)
df_all <- data.frame(
Page = as.numeric(999),
Company_Name=gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__subtitle"))),
Position_Name=gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__title"))),
Location_Name=gsub("\\W", "", html_text(html_nodes(pg, ".job-search-card__location"))),
stringsAsFactors=FALSE)
View(df_all)
# Scrape Page 0 through X (You Specify)
for (i in 0:9){
start_time <- Sys.time()
cat(".")
Sys.sleep(runif(1, min = 65, max = 129))
url_page_number <- paste0("&pageNum=", i)
url_read_html <- paste0(url_base_milwaukee, url_page_number)
pg <- read_html(url_read_html)
results <- data.frame(
Page = as.numeric(i),
Company_Name = gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__subtitle"))),
Position_Name = gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__title"))),
Location_Name = gsub("\\W", "", html_text(html_nodes(pg, ".job-search-card__location"))),
stringsAsFactors = FALSE)
df_all <- rbind(df_all, results)
end_time <- Sys.time()
time_needed <- end_time - start_time
print(paste("Step", i, "was finished after", time_needed, "seconds."))
}
View(df_all)
writeLines(unique(df_all$Company_Name), "exports/companies_milwaukee7.csv", sep = ",")
write.csv(df_all, "exports/Milwaukee7.csv")
require(rvest)
require(purrr)
require(dplyr)
# Scrape Once:
url_base_chicago <- "https://www.linkedin.com/jobs/search?keywords=Data&location=Greater%20Chicago%20Area&geoId=90000014&trk=public_jobs_jobs-search-bar_search-submit&position=1"
url_page_number <- paste0("&pageNum=", 0)
url_read_html <- paste0(url_base_chicago, url_page_number)
pg <- read_html(url_read_html)
df_all <- data.frame(
Page = as.numeric(999),
Position_Name=gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__subtitle"))),
Company_Name=gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__title"))),
Location_Name=gsub("\\W", "", html_text(html_nodes(pg, ".job-search-card__location"))),
stringsAsFactors=FALSE)
View(df_all)
# Scrape Page 0 through X (You Specify)
for (i in 0:9){
start_time <- Sys.time()
cat(".")
Sys.sleep(runif(1, min = 65, max = 129))
url_page_number <- paste0("&pageNum=", i)
url_read_html <- paste0(url_base_chicago, url_page_number)
pg <- read_html(url_read_html)
results <- data.frame(
Page = as.numeric(i),
Position_Name = gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__subtitle"))),
Company_Name = gsub("\\W", "", html_text(html_nodes(pg, ".base-search-card__title"))),
Location_Name = gsub("\\W", "", html_text(html_nodes(pg, ".job-search-card__location"))),
stringsAsFactors = FALSE)
df_all <- rbind(df_all, results)
end_time <- Sys.time()
time_needed <- end_time - start_time
print(paste("Step", i, "was finished after", time_needed, "seconds."))
}
View(df_all)
writeLines(unique(df_all$Company_Name), "exports/companies_chicago7.csv", sep = ",")
write.csv(df_all, "exports/Chicago7.csv")
